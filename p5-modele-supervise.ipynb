{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelisation supervisee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Pre-requis et Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/dataset-clean-v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns(text):\n",
    "    \"\"\"\n",
    "    Convertit une chaîne de caractères en liste de mots en remplaçant certains caractères spéciaux et en séparant les éléments.\n",
    "\n",
    "    Args:\n",
    "        text (str): La chaîne de caractères à traiter. Celle-ci peut contenir des crochets, des virgules et des guillemets.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste de mots extraits de la chaîne, avec les caractères spéciaux remplacés par des espaces.\n",
    "    \"\"\"\n",
    "    return text.replace(\"[\", \" \").replace(\"]\", \" \").replace(\",\", \" \").replace(\"'\", \" \").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction 'convert_columns' aux variables 'preproc_tags', 'preproc_body', 'preproc_title'\n",
    "\n",
    "df['preproc_title'] = df['preproc_title'].apply(convert_columns)\n",
    "df['preproc_body'] = df['preproc_body'].apply(convert_columns)\n",
    "df['preproc_tags'] = df['preproc_tags'].apply(convert_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour le pre-processing du texte\n",
    "\n",
    "# Charger le modèle de langue\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Liste des mots spécifiques à conserver (comme \"C++\", \"C#\", etc.)\n",
    "whitelist = [\"c#\", \"c++\"]\n",
    "\n",
    "# Fonction pour le traitement du texte\n",
    "def preprocess_text(text):\n",
    "    # Enlever les balises HTML\n",
    "    #soup = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    doc = nlp(text)  # Traiter le texte avec spaCy\n",
    "    \n",
    "    # Expression régulière pour vérifier les caractères anglais uniquement (ASCII)\n",
    "    def is_english(token):\n",
    "        return re.match(r'^[a-zA-Z0-9+.#]+$', token)\n",
    "\n",
    "    tokens = [\n",
    "        # Utiliser le lemme sauf si le mot est dans la whitelist\n",
    "        token.lemma_.lower() if token.lemma_.lower() not in whitelist else token.text.lower()\n",
    "        for token in doc \n",
    "        if not token.is_stop                         # Ne pas inclure les stopwords\n",
    "        and not token.is_punct                       # Ne pas inclure la ponctuation\n",
    "        and not token.like_num                       # Ne pas inclure les chiffres\n",
    "        and len(token.lemma_) >= 3                    # Exclure les tokens trop courts\n",
    "        and (is_english(token.text) or token.text.lower() in whitelist)  # Garder les mots anglais ou ceux de la whitelist\n",
    "    ]\n",
    "    print(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les listes 'preproc_body' et 'preproc_title'\n",
    "\n",
    "df['preproc_corpus'] = df.apply(lambda row: row['preproc_body'] + row['preproc_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de la variable 'corpus' qui regroupe les colonnes 'preproc_title' et 'preproc_body'\n",
    "\n",
    "df['corpus'] = df['preproc_title'].apply(lambda x: ' '.join(x)) + ' ' + df['preproc_body'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c#', 'java', 'c++', 'javascript', 'php', 'asp.net', 'iphone', 'jquery', 'python', 'sql', 'html', 'c', 'sql-server', 'objective-c', 'mysql', 'database', 'windows', 'wpf', 'linux', 'ajax', 'performance', 'xml', 'css', 'ruby-on-rails', 'ruby', 'asp.net-mvc', 'flash', 'cocoa-touch', 'multithreading', 'visual-studio', 'cocoa', 'image', 'django', 'macos', 'apache-flex', 'web-services', 'string', 'security', 'arrays', 'visual-studio-2008', 'actionscript-3', 'user-interface', 'vb.net', 'algorithm', 't-sql', 'hibernate', 'sql-server-2005', 'forms', 'eclipse', 'oracle', 'debugging', 'winforms', 'internet-explorer', 'file', 'winapi', 'unit-testing', 'http', 'parsing', 'json', 'xcode', 'events', 'spring', 'class', 'xaml', 'apache', 'linq', 'android', 'delphi', 'unix', 'authentication', 'data-binding', 'firefox', 'silverlight', 'optimization', 'ios', 'wcf', 'jakarta-ee', 'regex', 'oop', 'memory', 'gcc', 'orm', 'perl', 'network-programming', 'iis', 'shell', 'validation', 'swing', 'visual-c++', 'memory-management', 'scripting', 'caching', 'bash', 'svn', 'sockets', 'linq-to-sql', 'web-applications', 'exception', 'jpa', 'math']\n"
     ]
    }
   ],
   "source": [
    "# Compter la fréquence des tags dans toute la colonne 'preproc_tags'\n",
    "top_100_tags = [tag for tag, count in Counter(tag for tags in df['preproc_tags'] for tag in tags).most_common(100)]\n",
    "print(top_100_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc_title</th>\n",
       "      <th>preproc_tags</th>\n",
       "      <th>preproc_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[gettimeofday, guarantee, microsecond, resolut...</td>\n",
       "      <td>[linux, winapi, visual-c++, unix, timer]</td>\n",
       "      <td>[port, game, originally, write, win32, api, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[decode, sql, cast]</td>\n",
       "      <td>[c#, sql, vb.net, ascii, hex]</td>\n",
       "      <td>[recently, site, deluge, resurgence, asprox, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[display, flash, content, winforms, application]</td>\n",
       "      <td>[c#, winforms, flash, adobe, macromedia]</td>\n",
       "      <td>[good, way, display, flash, content, winforms,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sql, text, indexing, return, result, word, co...</td>\n",
       "      <td>[sql, sql-server, sql-server-2005, indexing, f...</td>\n",
       "      <td>[instance, query, like, follow, sql, server, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[unit, test, flex, application, ide, build, sc...</td>\n",
       "      <td>[apache-flex, eclipse, unit-testing, build-aut...</td>\n",
       "      <td>[currently, work, application, frontend, write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>[possible, prevent, iphone, ipad, orientation,...</td>\n",
       "      <td>[iphone, ipad, webkit, rotation, orientation]</td>\n",
       "      <td>[see, similar, question, issue, relate, native...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>[log, fatal, parse, error, php5]</td>\n",
       "      <td>[php, fatal-error, error-logging, parse-error,...</td>\n",
       "      <td>[write, error, log, service, integrate, websit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>[address, use, java]</td>\n",
       "      <td>[java, web-applications, jboss, ip-address, st...</td>\n",
       "      <td>[time, restart, application, build, java, stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>[selenium, testing]</td>\n",
       "      <td>[perl, selenium, selenium-rc, selenium-ide, gu...</td>\n",
       "      <td>[want, bunch, dom, object, xpath, loop, check,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>[flash, caroussel, xml, parse, html, link]</td>\n",
       "      <td>[html, xml, parsing, hyperlink, actionscript-2]</td>\n",
       "      <td>[hello, try, modify, carousel, script, flash, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           preproc_title  \\\n",
       "0      [gettimeofday, guarantee, microsecond, resolut...   \n",
       "1                                    [decode, sql, cast]   \n",
       "2       [display, flash, content, winforms, application]   \n",
       "3      [sql, text, indexing, return, result, word, co...   \n",
       "4      [unit, test, flex, application, ide, build, sc...   \n",
       "...                                                  ...   \n",
       "49995  [possible, prevent, iphone, ipad, orientation,...   \n",
       "49996                   [log, fatal, parse, error, php5]   \n",
       "49997                               [address, use, java]   \n",
       "49998                                [selenium, testing]   \n",
       "49999         [flash, caroussel, xml, parse, html, link]   \n",
       "\n",
       "                                            preproc_tags  \\\n",
       "0               [linux, winapi, visual-c++, unix, timer]   \n",
       "1                          [c#, sql, vb.net, ascii, hex]   \n",
       "2               [c#, winforms, flash, adobe, macromedia]   \n",
       "3      [sql, sql-server, sql-server-2005, indexing, f...   \n",
       "4      [apache-flex, eclipse, unit-testing, build-aut...   \n",
       "...                                                  ...   \n",
       "49995      [iphone, ipad, webkit, rotation, orientation]   \n",
       "49996  [php, fatal-error, error-logging, parse-error,...   \n",
       "49997  [java, web-applications, jboss, ip-address, st...   \n",
       "49998  [perl, selenium, selenium-rc, selenium-ide, gu...   \n",
       "49999    [html, xml, parsing, hyperlink, actionscript-2]   \n",
       "\n",
       "                                            preproc_body  \n",
       "0      [port, game, originally, write, win32, api, li...  \n",
       "1      [recently, site, deluge, resurgence, asprox, b...  \n",
       "2      [good, way, display, flash, content, winforms,...  \n",
       "3      [instance, query, like, follow, sql, server, s...  \n",
       "4      [currently, work, application, frontend, write...  \n",
       "...                                                  ...  \n",
       "49995  [see, similar, question, issue, relate, native...  \n",
       "49996  [write, error, log, service, integrate, websit...  \n",
       "49997  [time, restart, application, build, java, stru...  \n",
       "49998  [want, bunch, dom, object, xpath, loop, check,...  \n",
       "49999  [hello, try, modify, carousel, script, flash, ...  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['preproc_title', 'preproc_tags', 'preproc_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les tags dans 'preproc_tags' en ne gardant que ceux présents dans le top 100\n",
    "df['filtered_tags'] = df['preproc_tags'].apply(lambda tags: [tag for tag in tags if tag in top_100_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les individus qui n'ont plus de tags\n",
    "df = df[df['filtered_tags'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/vdumont/pCloud%20Drive/Formation%20OpenClassroom/Projets/Projet%205/mlruns/269961575685329476', creation_time=1727802178758, experiment_id='269961575685329476', last_update_time=1727802178758, lifecycle_stage='active', name='StackOverflow Tags Prediction 2', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparation de MLFLow\n",
    "mlflow.set_experiment(\"StackOverflow Tags Prediction 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preparation du jeu d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['corpus'], df['filtered_tags'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Regression Logistique avec Bag-of-Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"RegLog - BoW\"):\n",
    "    # Log des paramètres du modèle dans MLFlow\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    # Bag of Words sur le jeu d'entraînement X_train\n",
    "    vectorizer_bow = CountVectorizer()\n",
    "    X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
    "\n",
    "    # Préparer les étiquettes (tags) avec MultiLabelBinarizer sur le jeu d'entraînement y_train\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_mlb = mlb.fit_transform(y_train)\n",
    "\n",
    "    # Modelisation RegLog avec BoW\n",
    "    model_bow = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_bow.fit(X_train_bow, y_mlb)\n",
    "\n",
    "    # Predire les tags sur le jeu de test X_test\n",
    "    y_pred_bow = model_bow.predict(vectorizer_bow.transform(X_test))\n",
    "\n",
    "    # Préparer les étiquettes (tags) du jeu de test y_test\n",
    "    y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "    # Evaluation des performances du modèle avec Bag of Words\n",
    "\n",
    "    accuracy = accuracy_score(y_test_mlb, y_pred_bow)\n",
    "    precision = precision_score(y_test_mlb, y_pred_bow, average='weighted')\n",
    "    recall = recall_score(y_test_mlb, y_pred_bow, average='weighted')\n",
    "    f1 = f1_score(y_test_mlb, y_pred_bow, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model_bow, \"model_reglog_bow\")\n",
    "\n",
    "    print(f\"\"\"Regression Logistique avec Bag of Words :\n",
    "    Score Accuracy : {accuracy:.4f}\n",
    "    Score Precision : {precision:.4f}\n",
    "    Score Recall : {recall:.4f}\n",
    "    Score F1 : {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regression Logistique avec TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"RegLog - TF-IDF\"):\n",
    "    # Log des paramètres du modèle dans MLFlow\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    # TF-IDF sur le jeu d'entrainement X_train\n",
    "    vectorizer_tfidf = TfidfVectorizer()\n",
    "    X_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "\n",
    "    # Préparer les étiquettes (tags) avec MultiLabelBinarizer sur le jeu d'entraînement y_train\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_mlb = mlb.fit_transform(y_train)\n",
    "\n",
    "    # Modèle Regression Logistique avec TF-IDF\n",
    "    model_tfidf = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_tfidf.fit(X_tfidf, y_mlb)\n",
    "\n",
    "    # Predire les tags sur le jeu de test X_test\n",
    "    y_pred_tfidf = model_tfidf.predict(vectorizer_tfidf.transform(X_test))\n",
    "\n",
    "    # Préparer les étiquettes (tags) du jeu de test y_test\n",
    "    y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_mlb, y_pred_tfidf)\n",
    "    precision= precision_score(y_test_mlb, y_pred_tfidf, average='weighted')\n",
    "    recall = recall_score(y_test_mlb, y_pred_tfidf, average='weighted')\n",
    "    f1 = f1_score(y_test_mlb, y_pred_tfidf, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model_tfidf, \"model_reglog_tfidf\")\n",
    "\n",
    "    print(f\"\"\"Regression Logistique avec TF-IDF :\n",
    "    Score Accuracy : {accuracy:.4f}\n",
    "    Score Precision : {precision:.4f}\n",
    "    Score Recall : {recall:.4f}\n",
    "    Score F1 : {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_n_tags(input_sentence, vectorizer, model, mlb, n=5):\n",
    "    \"\"\"\n",
    "    Prédit les 'n' tags les plus probables pour une phrase d'entrée en utilisant le modèle et le vecteur BoW.\n",
    "\n",
    "    Args:\n",
    "        input_sentence (str): La phrase d'entrée à partir de laquelle prédire les tags.\n",
    "        vectorizer (CountVectorizer): Le vecteur BoW déjà ajusté sur le jeu d'entraînement.\n",
    "        model (OneVsRestClassifier): Le modèle de régression logistique ajusté.\n",
    "        mlb (MultiLabelBinarizer): L'encodeur MultiLabelBinarizer ajusté sur les étiquettes de tags.\n",
    "        n (int): Le nombre de tags à prédire (par défaut 5).\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste des 'n' tags les plus probables pour l'entrée.\n",
    "    \"\"\"\n",
    "\n",
    "    # Transformer la phrase en BoW\n",
    "    X_input_bow = vectorizer.transform([input_sentence])\n",
    "\n",
    "    # Obtenir les probabilités des prédictions\n",
    "    y_pred_prob = model.predict_proba(X_input_bow)\n",
    "\n",
    "    # Sélectionner les indices des 'n' tags les plus probables\n",
    "    top_n_indices = np.argsort(y_pred_prob[0])[-n:]\n",
    "\n",
    "    # Convertir ces indices en tags\n",
    "    top_n_tags = mlb.classes_[top_n_indices]\n",
    "\n",
    "    # Retourner les 'n' tags prédits\n",
    "    return list(top_n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"How to compile a C programm using gcc in Ubuntu?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation sur le Bag of Words (BoW):\n",
    "top_n = 5  # Par exemple, choisir 3 tags\n",
    "top_n_predicted_tags = predict_top_n_tags(input_sentence, vectorizer_bow, model_bow, mlb, n=top_n)\n",
    "print(f\"Les {top_n} tags prédits pour la phrase '{input_sentence}' sont : {top_n_predicted_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation sur le TF-IDF :\n",
    "top_n = 5  # Par exemple, choisir 3 tags\n",
    "top_n_predicted_tags = predict_top_n_tags(input_sentence, vectorizer_tfidf, model_tfidf, mlb, n=top_n)\n",
    "print(f\"Les {top_n} tags prédits pour la phrase '{input_sentence}' sont : {top_n_predicted_tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regression Logistique avec Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation du corpus pour Word2Vec (supposant que chaque document est une liste de tokens)\n",
    "sentences_train = [doc.split() for doc in X_train]\n",
    "sentences_test = [doc.split() for doc in X_test]\n",
    "\n",
    "# Entraînement du modèle Word2Vec\n",
    "w2v_model = Word2Vec(sentences=sentences_train, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Fonction pour obtenir la moyenne des embeddings d'un document\n",
    "def get_avg_word2vec(tokens_list, vector, size):\n",
    "    # On garde les vecteurs uniquement des tokens présents dans le vocabulaire de Word2Vec\n",
    "    valid_words = [word for word in tokens_list if word in vector.wv.index_to_key]\n",
    "    if len(valid_words) == 0:  # Si aucun mot n'est reconnu, retourner un vecteur nul\n",
    "        return np.zeros(size)\n",
    "    return np.mean([vector.wv[word] for word in valid_words], axis=0)\n",
    "\n",
    "# Calculer les embeddings moyens pour chaque document\n",
    "X_train_w2v = np.array([get_avg_word2vec(doc.split(), w2v_model, 100) for doc in X_train])\n",
    "X_test_w2v = np.array([get_avg_word2vec(doc.split(), w2v_model, 100) for doc in X_test])\n",
    "\n",
    "# Préparer les étiquettes (tags) avec MultiLabelBinarizer sur le jeu d'entraînement y_train\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_mlb = mlb.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"RegLog - Word2Vec\"):\n",
    "    # Log des paramètres du modèle dans MLFlow\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    # Modélisation RegLog avec Word2Vec\n",
    "    model_w2v = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "    model_w2v.fit(X_train_w2v, y_mlb)\n",
    "\n",
    "    # Prédire les tags sur le jeu de test X_test\n",
    "    y_pred_w2v = model_w2v.predict(X_test_w2v)\n",
    "\n",
    "    # Préparer les étiquettes (tags) du jeu de test y_test\n",
    "    y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_mlb, y_pred_w2v)\n",
    "    precision = precision_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "    recall = recall_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "    f1 = f1_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model_w2v, \"model_reglog_word2vec\")\n",
    "\n",
    "    print(f\"\"\"Regression Logistique avec Word2Vec :\n",
    "    Score Accuracy : {accuracy:.4f}\n",
    "    Score Precision : {precision:.4f}\n",
    "    Score Recall : {recall:.4f}\n",
    "    Score F1 : {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. DecisionTreeClassifier avec Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"DecisionTreeClassifier - Word2Vec\"):\n",
    "    # Modélisation DecisionTreeClassifier avec Word2Vec\n",
    "    model_w2v_decisiontree = OneVsRestClassifier(DecisionTreeClassifier())\n",
    "    model_w2v_decisiontree.fit(X_train_w2v, y_mlb)\n",
    "\n",
    "    # Prédire les tags sur le jeu de test X_test\n",
    "    y_pred_w2v = model_w2v_decisiontree.predict(X_test_w2v)\n",
    "\n",
    "    # Préparer les étiquettes (tags) du jeu de test y_test\n",
    "    y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_mlb, y_pred_w2v)\n",
    "    precision = precision_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "    recall = recall_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "    f1 = f1_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model_bow, \"model_decisiontree_word2vec\")\n",
    "\n",
    "    print(f\"\"\"Arbre de décision avec Word2Vec :\n",
    "    Score Accuracy : {accuracy:.4f}\n",
    "    Score Precision : {precision:.4f}\n",
    "    Score Recall : {recall:.4f}\n",
    "    Score F1 : {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour prédire les X tags les plus probables d'une nouvelle phrase\n",
    "def predict_top_tags(phrase, w2v_model, classifier, mlb, vector_size=100, top_n=5):\n",
    "    # Prétraitement de la phrase (tokenisation)\n",
    "    tokens = preprocess_text(phrase)\n",
    "    \n",
    "    # Calculer la moyenne des embeddings de la phrase\n",
    "    phrase_embedding = get_avg_word2vec(tokens, w2v_model, vector_size)\n",
    "    \n",
    "    # Le classificateur a besoin d'un tableau 2D, donc on reshape le vecteur\n",
    "    phrase_embedding = phrase_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Obtenir les probabilités des prédictions\n",
    "    y_pred_proba = classifier.predict_proba(phrase_embedding)\n",
    "    \n",
    "    # Sélectionner les indices des X plus grandes probabilités\n",
    "    top_n_indices = np.argsort(y_pred_proba[0])[-top_n:][::-1]\n",
    "    \n",
    "    # Récupérer les tags correspondants à ces indices\n",
    "    top_n_tags = mlb.classes_[top_n_indices]\n",
    "    \n",
    "    return top_n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction de tags avec Regression Logistique et Word2Vec\n",
    "phrase_input = \"How to compile a C programm using gcc in Ubuntu?\"\n",
    "top_n_tags = predict_top_tags(phrase_input, w2v_model, model_w2v, mlb, top_n=5)\n",
    "\n",
    "print(f\"RegLog W2V - Top 3 tags prédits pour la phrase '{phrase_input}': {top_n_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction de tags avec DecisitonTreeClassifier et Word2Vec\n",
    "phrase_input = \"How to compile a C programm using gcc in Ubuntu?\"\n",
    "top_n_tags = predict_top_tags(phrase_input, w2v_model, model_w2v_decisiontree, mlb, top_n=5)\n",
    "\n",
    "print(f\"DecisionTree W2V - Top 3 tags prédits pour la phrase '{phrase_input}': {top_n_tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "model_type = \"bert-base-uncased\"\n",
    "model = TFAutoModel.from_pretrained(model_type)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "def get_embeddings_in_batches(texts, batch_size=16):\n",
    "    embeddings_list = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        tokens = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='tf')\n",
    "        batch_embeddings = model(tokens['input_ids'])['pooler_output']\n",
    "        embeddings_list.append(batch_embeddings)\n",
    "    return tf.concat(embeddings_list, axis=0)\n",
    "\n",
    "X_train_list = X_train.tolist()\n",
    "X_test_list = X_test.tolist()\n",
    "\n",
    "X_train_emdebbing = get_embeddings_in_batches(X_train_list, batch_size=32)\n",
    "X_test_emdebbing = get_embeddings_in_batches(X_test_list, batch_size=32)\n",
    "\n",
    "# Modélisation Regression Logistique avec BERT\n",
    "model_bert_reglog = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "model_bert_reglog.fit(X_train_emdebbing, y_mlb)\n",
    "\n",
    "# Prédire les tags sur le jeu de test X_test\n",
    "y_pred_w2v = model_bert_reglog.predict(X_test_emdebbing)\n",
    "\n",
    "# Préparer les étiquettes (tags) du jeu de test y_test\n",
    "y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_mlb, y_pred_w2v)\n",
    "precision = precision_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "recall = recall_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "f1 = f1_score(y_test_mlb, y_pred_w2v, average='weighted')\n",
    "\n",
    "print(f\"\"\"Regression Logistique avec BERT :\n",
    "Score Accuracy : {accuracy:.4f}\n",
    "Score Precision : {precision:.4f}\n",
    "Score Recall : {recall:.4f}\n",
    "Score F1 : {f1:.4f}\"\"\")\n",
    "\n",
    "import pickles\n",
    "with open('models/model-bert-reglog.pkl', 'wb') as f:\n",
    "    pickle.dump(model_bert_reglog, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "model_type = \"bert-base-uncased\"\n",
    "model = TFAutoModel.from_pretrained(model_type)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "def get_embeddings_in_batches(texts, batch_size=16):\n",
    "    embeddings_list = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        tokens = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='tf')\n",
    "        batch_embeddings = model(tokens['input_ids'])['pooler_output']\n",
    "        embeddings_list.append(batch_embeddings)\n",
    "    return tf.concat(embeddings_list, axis=0)\n",
    "\n",
    "with mlflow.start_run(run_name=\"RegLog - BERT\"):\n",
    "    # Chargement du modele BERT RegLog\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    model_bert_reglog, X_test_emdebbing, y_pred_bert = joblib.load('models/model_bert_relog.joblib')\n",
    "\n",
    "    y_pred_bert = model_bert_reglog.predict(X_test_emdebbing)\n",
    "    y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_mlb, y_pred_bert)\n",
    "    precision = precision_score(y_test_mlb, y_pred_bert, average='weighted')\n",
    "    recall = recall_score(y_test_mlb, y_pred_bert, average='weighted')\n",
    "    f1 = f1_score(y_test_mlb, y_pred_bert, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model_bert_reglog, \"model_bert_reglog\")\n",
    "\n",
    "    print(f\"\"\"Regression Logistique avec BERT :\n",
    "    Score Accuracy : {accuracy:.4f}\n",
    "    Score Precision : {precision:.4f}\n",
    "    Score Recall : {recall:.4f}\n",
    "    Score F1 : {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Fonction pour générer les embeddings USE\n",
    "def get_use_embeddings(texts):\n",
    "    embeddings = use_model(texts)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_use = get_use_embeddings(X_train.tolist())\n",
    "X_test_use = get_use_embeddings(X_test.tolist())\n",
    "\n",
    "model_use_reglog = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "model_use_reglog.fit(X_train_use, y_mlb)\n",
    "\n",
    "y_pred_use = model_use_reglog.predict(X_test_use)\n",
    "\n",
    "# Préparer les étiquettes (tags) du jeu de test y_test\n",
    "y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test_mlb, y_pred_use)\n",
    "precision = precision_score(y_test_mlb, y_pred_use, average='weighted')\n",
    "recall = recall_score(y_test_mlb, y_pred_use, average='weighted')\n",
    "f1 = f1_score(y_test_mlb, y_pred_use, average='weighted')\n",
    "\n",
    "print(f\"\"\"Regression Logistique avec Bag of Words :\n",
    "Score Accuracy : {accuracy:.4f}\n",
    "Score Precision : {precision:.4f}\n",
    "Score Recall : {recall:.4f}\n",
    "Score F1 : {f1:.4f}\"\"\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('models/model-use-reglog.pkl', 'wb') as f:\n",
    "    pickle.dump(model_use_reglog, f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run(run_name=\"RegLog - BERT\"):\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    # Chargement du modele USE RegLog\n",
    "    model_use_reglog, X_test_use, y_pred_use = joblib.load('models/model_use_relog.joblib')\n",
    "\n",
    "    y_pred_use = model_bert_reglog.predict(X_test_use)\n",
    "    y_test_mlb = mlb.transform(y_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_mlb, y_pred_use)\n",
    "    precision = precision_score(y_test_mlb, y_pred_use, average='weighted')\n",
    "    recall = recall_score(y_test_mlb, y_pred_use, average='weighted')\n",
    "    f1 = f1_score(y_test_mlb, y_pred_use, average='weighted')\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model_bert_reglog, \"model_use_reglog\")\n",
    "\n",
    "    print(f\"\"\"Regression Logistique avec USE :\n",
    "    Score Accuracy : {accuracy:.4f}\n",
    "    Score Precision : {precision:.4f}\n",
    "    Score Recall : {recall:.4f}\n",
    "    Score F1 : {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-Pfk8s4i7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
